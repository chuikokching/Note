DMS(Kafka)

1.消息队列 日常例子：记录网站的用户行为 点击的按钮 搜过的关键词 将这些行为集合起来 即可生成用户logs日志文件 然后传递到Nginx日志采集服务器 再到Kafka消息队列 这些消息即可等待其他日志分析服务器来提取.

2.通常用于临时存储消息

3.应用场景:
  (1).异步处理
      例子：用户注册
           用户提交注册信息-->保存信息到数据库-->发送验证短信-->发送邮件-->反馈用户 
           导致用户等待时间过长 
                                          发送验证短信 发送邮件   
                                                    |
                                                    |
                                                    V              
           用户提交注册信息-->保存信息到数据库-->发送到消息队列-->反馈用户
           迅速响应用户 短信 邮件延迟能接受

  (2).系统解耦
      例子：双十一秒杀活动
            下单系统-->库存系统 订单系统直接调用库存系统,耦合程度高,库存系统崩溃容易造成连锁反应

            下单系统-->消息队列-->库存系统
            降低耦合,库存系统从消息队列中提取信息

  (3).流量削峰
      例子：订票系统
            过多的用户请求容易压垮服务器
            用户请求进入消息队列(低延迟,高吞吐),用户强行进入等待时间,降低服务器压力 其他服务器从消息队列中提取信息

  (4).日志处理
      例子：记录用户行为
            直接将用户日志logs存放到消息队列当中

4.消息队列两个模型
  生产者,消费者模型 (解耦)
  (1).点对点模式
      a.每个消息只有一个接收者 消息被消费就不在队列中
      b.发送者和接收者没有依赖关系 
      c.接收者在成功消费后会反馈,以便队列删除消息
  (2).发布订阅模式
      a. 每个消息可以有多个订阅者
      b. 发布者和订阅者有时间依赖,消费者需要先订阅某个topic,才能消费生产者的消息
      c. 消费者需要提前订阅topic,并保持在线运行


5.Kafka集群必须要有Zookeeper,先启动Zookeeper,再启动Kafka
  a.publish and subscribe
  b.store
  c.process


生产者(把数据推送给broker中的topic) -> Zookeeper集群,保存着Kafka相关的一些数据,比如offset,以及broker的集群状态 Kafka集群当中含有多个broker1,2,3,从而实现负载均衡以及容错 每个对应一个Kafka进程 -> 消费者组(从broker的topic当中提取数据) 1个消费者组可以含有多个消费者,而且一个消费者组拥有唯一ID,组内消费者一起消费订阅主题的所有分区(partition)信息

topic可以按照业务逻辑来组织 比如支付消息 商品消息 一个topic可包含多个partition,一个topic中的消息可以分布在topic的不同partition中

partition 0:0 1 2 3 4 5 6
partition 1:0 1 2
partition 2:0 1 2 3 
partition 3:0 1 2 3 4 5
offset记录每个消费者的偏移量,下次重启时能继续拉取信息,无需在原partition重新开始 *在分区中才有意义,分区间没意义