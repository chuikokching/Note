DMS(Kafka)

1.消息队列 日常例子：记录网站的用户行为 点击的按钮 搜过的关键词 将这些行为集合起来 即可生成用户logs日志文件 然后传递到Nginx日志采集服务器 再到Kafka消息队列 这些消息即可等待其他日志分析服务器来提取.

2.通常用于临时存储消息

3.应用场景:
  (1).异步处理
      例子：用户注册
           用户提交注册信息-->保存信息到数据库-->发送验证短信-->发送邮件-->反馈用户 
           导致用户等待时间过长 
                                          发送验证短信 发送邮件   
                                                    |
                                                    |
                                                    V              
           用户提交注册信息-->保存信息到数据库-->发送到消息队列-->反馈用户
           迅速响应用户 短信 邮件延迟能接受

  (2).系统解耦
      例子：双十一秒杀活动
            下单系统-->库存系统 订单系统直接调用库存系统,耦合程度高,库存系统崩溃容易造成连锁反应

            下单系统-->消息队列-->库存系统
            降低耦合,库存系统从消息队列中提取信息

  (3).流量削峰
      例子：订票系统
            过多的用户请求容易压垮服务器
            用户请求进入消息队列(低延迟,高吞吐),用户强行进入等待时间,降低服务器压力 其他服务器从消息队列中提取信息

  (4).日志处理
      例子：记录用户行为
            直接将用户日志logs存放到消息队列当中

4.消息队列两个模型
  生产者,消费者模型 (解耦)
  (1).点对点模式
      a.每个消息只有一个接收者 消息被消费就不在队列中
      b.发送者和接收者没有依赖关系 
      c.接收者在成功消费后会反馈,以便队列删除消息
  (2).发布订阅模式
      a. 每个消息可以有多个订阅者
      b. 发布者和订阅者有时间依赖,消费者需要先订阅某个topic,才能消费生产者的消息
      c. 消费者需要提前订阅topic,并保持在线运行


5.Kafka集群必须要有Zookeeper,先启动Zookeeper,再启动Kafka
  a.publish and subscribe
  b.store
  c.process


生产者(把数据推送给broker中的topic) -> Zookeeper集群,保存着Kafka相关的一些数据,比如offset,以及broker的集群状态 Kafka集群当中含有多个broker1,2,3,从而实现负载均衡以及容错 每个对应一个Kafka进程 -> 消费者组(从broker的topic当中提取数据) 1个消费者组可以含有多个消费者,而且一个消费者组拥有唯一ID,组内消费者一起消费订阅主题的所有分区(partition)信息

Zookeeper(kafka(broker(topic(partition))))

topic可以按照业务逻辑来组织 比如支付消息 商品消息 一个topic可包含多个partition,一个topic中的消息可以分布在topic的不同partition中

partition 0:0 1 2 3 4 5 6
partition 1:0 1 2
partition 2:0 1 2 3 
partition 3:0 1 2 3 4 5
offset记录每个消费者的偏移量,下次重启时能继续拉取信息,无需在原partition重新开始 *在分区中才有意义,分区间没意义


#Kafka命令
增加主题 
查看主题
删除主题
查看数据堆积量

新建topic 华为云 现网新增业务topic 根据名称新建topic
ru-cbg-ccpc-kafka   partition 6(比应用实例要多) replicas 3 aging time 168 
查看主从库 master-server-id (主库ip地址)
/data/mycat/bin/mycat restart
tail -100f wrapper.log   #检查mycat是否重启成功

发包后在跳板机上(200.200)用curl脚本语句验证ccpc,ccpcsp启动是否成功
!1019-!1025 #方便快捷 
在ccpcsp新发包的机器(212.84)上用curl(kafka topic专用检测语句)脚本语句验证新topic启动是否成功
在华为云ru-cbg-ccpc-kafka message query当中能看到对应刚才测试topic的partition数量

德国在kafka机器bin文件夹中执行增加主题命令
同样在新发包的机器ccpcsp机器中运行专用检测topic的curl语句
kafka(没上云)集群验证(message query) consumeroffsetchecker 
发包后在跳板机上(120.4)用curl脚本语句验证ccpc,ccpcsp启动是否成功


#kafka部署：
修改 kafka2.0.1/config/server.properties文件中ip地址信息，包括kafka和zookeeper的
启动zookeeper，启动kafka
./start_zk.sh
./start_kafka.sh
